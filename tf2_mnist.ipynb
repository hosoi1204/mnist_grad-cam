{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tf2_mnist.ipynb","provenance":[],"collapsed_sections":["5ITx3xc65xNI"],"mount_file_id":"1WIFCEq5ept-8kUMRHhCTsKdQh7RvaD9h","authorship_tag":"ABX9TyMYzO8r3SYbdjPEAvMnx3lU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"ht7wFzmg2N8d"},"source":["# tf2.0でmnistの学習とGrad-CAMの実装"]},{"cell_type":"markdown","metadata":{"id":"LfVh1sYh2Vmz"},"source":["## 学習"]},{"cell_type":"markdown","metadata":{"id":"5ITx3xc65xNI"},"source":["### tfのversion確認"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"H-SisIxY2Ysh","executionInfo":{"status":"ok","timestamp":1610042138427,"user_tz":-540,"elapsed":1986,"user":{"displayName":"耳栓","photoUrl":"","userId":"17474327468081351261"}},"outputId":"2ad5c4bd-cf46-4302-fdf1-c95e6825c66c"},"source":["import tensorflow as tf\r\n","tf.__version__"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'2.4.0'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"t75ECWjt5zgP"},"source":["### モデル定義"]},{"cell_type":"code","metadata":{"id":"fxav-GFR2kaZ","executionInfo":{"status":"ok","timestamp":1610052024881,"user_tz":-540,"elapsed":627,"user":{"displayName":"耳栓","photoUrl":"","userId":"17474327468081351261"}}},"source":["from tensorflow.keras import layers\r\n","\r\n","class Classifier(tf.keras.Model):\r\n","  def __init__(self):\r\n","    super().__init__()\r\n","    # 使用するLayerの定義\r\n","    self.conv0 = layers.Conv2D(8, (3, 3), padding='same', activation='relu', name='conv_1')\r\n","    self.mp0 = layers.MaxPooling2D(pool_size=(2, 2), name='maxpool_1')\r\n","    self.conv1 = layers.Conv2D(32, (3, 3), strides=2, padding='same', activation='relu', name='conv_2')\r\n","    self.flatten = layers.Flatten()\r\n","    self.l1 = layers.Dense(128, activation='relu', name='dense_1')\r\n","    self.l2 = layers.Dense(10, activation='softmax', name='dense_2')\r\n","  \r\n","  def call(self, inputs):\r\n","    x = self.conv0(inputs)\r\n","    x = self.mp0(x)\r\n","    x = self.conv1(x)\r\n","    x = self.flatten(x)\r\n","    x = self.l1(x)\r\n","    x = self.l2(x)\r\n","\r\n","    return x\r\n","  \r\n","  '''\r\n","  subclassing apiではモデルのinputやoutputを明示してないため、\r\n","  のちのちmodel.get_layerを使用して中間層を取得できない。\r\n","  そのため、中間層を出力するメソッドを作成する。\r\n","  @tf.functionをつけることで計算グラフが構築された状態になるので、\r\n","  savedmodel形式で保存したときに、この関数まで保存されるのかな？\r\n","  @tf.functionつけないと後々メソッドが呼び出せない.\r\n","  追記：最終的に使わなかった、\r\n","  '''\r\n","  @tf.function(input_signature=[tf.TensorSpec([None, 28, 28, 1], tf.float32)])\r\n","  def get_conv1_output(self, inputs):\r\n","    x = self.conv0(inputs)\r\n","    x = self.mp0(x)\r\n","    conv1 = self.conv1(x)\r\n","    x = self.flatten(conv1)\r\n","    x = self.l1(x)\r\n","    x = self.l2(x)\r\n","    return x, conv1"],"execution_count":75,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bN8ZNw5H51U-"},"source":["### mnist_datasetの準備"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qqFkO7T04XXs","executionInfo":{"status":"ok","timestamp":1610047683436,"user_tz":-540,"elapsed":796,"user":{"displayName":"耳栓","photoUrl":"","userId":"17474327468081351261"}},"outputId":"a46744d5-1f2a-4fa1-d406-f63235c54256"},"source":["import numpy as np\r\n","(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\r\n","x_train = x_train[:,:,:, np.newaxis] / 255.0\r\n","x_test = x_test[:,:,:, np.newaxis] / 255.0\r\n","print(x_train.shape)\r\n","print(x_test.shape)\r\n","\r\n","# tf.dataによるデータセット作成\r\n","train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\r\n","train_dataset = train_dataset.shuffle(buffer_size=60000).batch(128)\r\n","\r\n","test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\r\n","test_dataset = test_dataset.batch(128)\r\n"],"execution_count":28,"outputs":[{"output_type":"stream","text":["(60000, 28, 28, 1)\n","(10000, 28, 28, 1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ymoRfbSg5-bG"},"source":["### Main"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PWVuYpj959cm","executionInfo":{"status":"ok","timestamp":1610052040023,"user_tz":-540,"elapsed":10891,"user":{"displayName":"耳栓","photoUrl":"","userId":"17474327468081351261"}},"outputId":"a9b82067-303a-4471-c3bf-fb643a7c0870"},"source":["model = Classifier()\r\n","loss = tf.keras.losses.SparseCategoricalCrossentropy()\r\n","train_acc = tf.keras.metrics.SparseCategoricalAccuracy()\r\n","test_acc = tf.keras.metrics.SparseCategoricalAccuracy()\r\n","opt = tf.keras.optimizers.Adam()\r\n","EPOCH = 5\r\n","\r\n","@tf.function\r\n","def train_on_batch(x, y):\r\n","  with tf.GradientTape() as tape:\r\n","    pred = model(x)\r\n","    loss_val = loss(y, pred)\r\n","\r\n","  # backward\r\n","  gradients = tape.gradient(loss_val, model.trainable_weights)\r\n","  # step optimizer\r\n","  opt.apply_gradients(zip(gradients, model.trainable_weights))\r\n","  # update accuracy\r\n","  train_acc.update_state(y, pred)\r\n","\r\n","  return loss_val\r\n","\r\n","@tf.function\r\n","def test_on_batch(x, y):\r\n","  pred = model(x)\r\n","  loss_val = loss(y, pred)\r\n","  test_acc.update_state(y, pred)\r\n","  return loss_val\r\n","\r\n","# train\r\n","for i in range(EPOCH):\r\n","  # 評価関数のリセット\r\n","  train_acc.reset_states()\r\n","  test_acc.reset_states()\r\n","  print(\"Epoch=\", i)\r\n","\r\n","  for step, (x, y) in enumerate(train_dataset):\r\n","    loss_val = train_on_batch(x, y)\r\n","\r\n","    print(\"\\rstep={0}, loss={1}, total accuracy={2}\".format(step, loss_val, train_acc.result()), end=\"\")\r\n","  \r\n","  for (x, y) in test_dataset:\r\n","    loss_val = test_on_batch(x, y)\r\n","  print(\"\\ntest_val={0}, test accuracy={1}\".format(loss_val, test_acc.result()))\r\n","\r\n","# save model\r\n","model.save('/content/drive/MyDrive/mnist/model/')"],"execution_count":76,"outputs":[{"output_type":"stream","text":["Epoch= 0\n","step=468, loss=0.04126186668872833, total accuracy=0.9223166704177856\n","test_val=0.030652616173028946, test accuracy=0.9688000082969666\n","Epoch= 1\n","step=468, loss=0.06372872740030289, total accuracy=0.973883330821991\n","test_val=0.0037276349030435085, test accuracy=0.9757999777793884\n","Epoch= 2\n","step=468, loss=0.1473265290260315, total accuracy=0.9814666509628296\n","test_val=0.0007890762062743306, test accuracy=0.9814000129699707\n","Epoch= 3\n","step=468, loss=0.07757005095481873, total accuracy=0.9851833581924438\n","test_val=0.0015517963329330087, test accuracy=0.9832000136375427\n","Epoch= 4\n","step=468, loss=0.026307426393032074, total accuracy=0.9882500171661377\n","test_val=0.0017825148534029722, test accuracy=0.984499990940094\n","INFO:tensorflow:Assets written to: /content/drive/MyDrive/mnist/model/assets\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rSyTihk1BqJ4"},"source":["## Grad-CAM\r\n"]},{"cell_type":"markdown","metadata":{"id":"r8SAuCdJDJEL"},"source":["### モデルの確認"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aJCKrKKVBvZ2","executionInfo":{"status":"ok","timestamp":1610052049584,"user_tz":-540,"elapsed":564,"user":{"displayName":"耳栓","photoUrl":"","userId":"17474327468081351261"}},"outputId":"7ccd2991-b615-4c32-f26d-fae4b13657fc"},"source":["import tensorflow as tf\r\n","model_path = \"/content/drive/MyDrive/mnist/model\"\r\n","model = tf.keras.models.load_model(model_path)\r\n","model.summary()"],"execution_count":77,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n","Model: \"classifier_19\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv_1 (Conv2D)              multiple                  80        \n","_________________________________________________________________\n","maxpool_1 (MaxPooling2D)     multiple                  0         \n","_________________________________________________________________\n","conv_2 (Conv2D)              multiple                  2336      \n","_________________________________________________________________\n","flatten_19 (Flatten)         multiple                  0         \n","_________________________________________________________________\n","dense_1 (Dense)              multiple                  200832    \n","_________________________________________________________________\n","dense_2 (Dense)              multiple                  1290      \n","=================================================================\n","Total params: 204,538\n","Trainable params: 204,538\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZbpztmuOD8tf"},"source":["### Main"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"ZY68iSPP1XOi","executionInfo":{"status":"ok","timestamp":1610107445863,"user_tz":-540,"elapsed":1314,"user":{"displayName":"耳栓","photoUrl":"","userId":"17474327468081351261"}},"outputId":"119426e0-70f8-4469-a145-a4f5cd5faa86"},"source":["import cv2\r\n","import numpy as np\r\n","import tensorflow as tf\r\n","import matplotlib.pyplot as plt\r\n","\r\n","class Grad_Model(tf.keras.Model):\r\n","  def __init__(self, t_model):\r\n","    super().__init__()\r\n","    # 使用するLayerの定義\r\n","    self.conv0 = t_model.conv0\r\n","    self.mp0 = t_model.mp0\r\n","    self.conv1 = t_model.conv1\r\n","    self.flatten = t_model.flatten\r\n","    self.l1 = t_model.l1\r\n","    self.l2 = t_model.l2\r\n","\r\n","  def call(self, inputs):\r\n","    x = self.conv0(inputs)\r\n","    x = self.mp0(x)\r\n","    conv_out = self.conv1(x)\r\n","    x = self.flatten(conv_out)\r\n","    x = self.l1(x)\r\n","    x = self.l2(x)\r\n","    return x, conv_out # Grad-CAMで見たいconv層の出力も返す\r\n","\r\n","def GradCam(model, img, label):\r\n","  grad_model = Grad_Model(model) # 勾配計算用にモデルを生成\r\n","\r\n","  # 勾配の計算\r\n","  with tf.GradientTape() as tape:\r\n","    predictions, conv_outputs = grad_model(np.array([img]))\r\n","    class_out = predictions[:, label]\r\n","  output = conv_outputs[0]\r\n","  grads = tape.gradient(class_out, conv_outputs)[0]\r\n","\r\n","  # ここの3文はよくわからなかった\r\n","  gate_f = tf.cast(output > 0, 'float32')\r\n","  gate_r = tf.cast(grads > 0, 'float32')\r\n","  guided_grads = tf.cast(output > 0, 'float32') * tf.cast(grads > 0, 'float32') * grads\r\n","\r\n","  weights = tf.reduce_mean(guided_grads, axis=(0, 1))\r\n","\r\n","  cam = np.zeros(output.shape[0: 2], dtype = np.float32)\r\n","\r\n","  for i, w in enumerate(weights):\r\n","      cam += w * output[:, :, i]\r\n","\r\n","  # 得られたヒートマップを成形して画像として保存と表示\r\n","  cam = cv2.resize(cam.numpy(), (28, 28))\r\n","  cam = np.maximum(cam, 0)\r\n","  heatmap = (cam - cam.min()) / (cam.max() - cam.min())\r\n","\r\n","  cam = cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_JET)\r\n","  \r\n","  output_image = cv2.addWeighted(cv2.cvtColor(img.astype('uint8'), cv2.COLOR_RGB2BGR), 0.5, cam, 1, 0)\r\n","  \r\n","  cv2.imwrite('/content/drive/MyDrive/mnist/test.png', output_image)\r\n","  output_image = cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB)\r\n","  plt.imshow(output_image)\r\n","  plt.show()\r\n","\r\n","def main():\r\n","  model_path = \"/content/drive/MyDrive/mnist/model\"\r\n","  model = tf.keras.models.load_model(model_path)\r\n","\r\n","  (_,_), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\r\n","  x_test = x_test[:,:,:, np.newaxis] / 255.0\r\n","  img = x_test[0]\r\n","  label = y_test[0]\r\n","\r\n","  heatmap = GradCam(model, img, label)\r\n","\r\n","if __name__ == \"__main__\":\r\n","  main()"],"execution_count":21,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]}]}